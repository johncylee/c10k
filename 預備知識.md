# 預備知識

針對 [Book to Read First](http://www.kegel.com/c10k.html#books) 提到的參考資料重點摘錄。

## [Unix Network Programming, Volume 1][]

手頭上是第三版，6.2 提到 UNIX 下有五種 I/O models:

* blocking I/O
* nonblocking I/O
* I/O multiplexing (`select` and `poll`)
* signal driven I/O (`SIGIO`)
* asynchronous I/O (the POSIX `aio_` functions)

常見的 blocking 略過不論，nonblocking 指的是 file descriptor 有設定 `O_NONBLOCK`，所以在存取將導致等待時，直接回傳 `EWOULDBLOCK`。POSIX.1 說回傳 `EAGAIN` 也可以，所以兩者都要檢查。這樣雖然不會 block 了，但是不知道何時可以嘗試，隔一段時間重試也沒效率，所以還需搭配其他方式。

I/O multiplexing 是指利用 `select`/`poll` 來等待 file descriptor 「就緒」。`select` 的 man page 註明它是 _synchronous I/O multiplexing_，仍然是 blocking，所以在單獨一個 fd 時此法沒有好處，多個 fd 時才有。底下一段附註很有意思：

> Another closely related I/O model is to use multithreading with blocking I/O. That model very closely resembles the model described above, except that instead of using `select` to block on multiple file descriptors, the program uses multiple threads (one per file descriptor), and each thread is then free to call blocking system calls like `recvfrom`.

也就是開多個 thread 然後一樣使用 blocking 方式。

Signal driven I/O 指 fd 設定了 `O_ASYNC`，這樣當 fd 就緒時會產生 `SIGIO`，這時就可由 signal handler 來處理。相對於 I/O multiplexing，此法差異是完全沒有 block，等收到 signal 再來處理即可。

Asynchronous I/O 則是把整個存取，包括把資料在 kernel 與 user space 間的傳送都做完後，才發出通知。他與 signal driven I/O 的不同是，signal driven 是在可以「開始」時通知，而 asynchronous I/O 是「完成」後通知。

### Synchronous I/O versus Asynchronous I/O

這裡寫到 POSIX 對兩者的定義：

* A _synchronous I/O operation_ causes the requesting process to be blocked until that I/O operation completes.
* A _asynchronous I/O operation_ does not cause the requesting process to be blocked.

按照此定義，blocking / nonblocking / I/O multiplexing / signal-driven 全部都是 synchronous，因為當 I/O 實際發生時仍然會 block。

## [The 'thundering herd' problem][]

Unix Network Programming 在 Chap.30 Client/Server Design Alternatives 裡提到此問題，主要是針對 `accept`，Linux kernel 雖已修正，但類似模式在其他地方也會發生，例如 [Add epoll round robin wakeup mode][]，所以仍有必要理解。可參考 [Wikipedia](https://en.wikipedia.org/wiki/Thundering_herd_problem) 上的簡單說明。

## [Jeff Darcy's notes on high-performance server design][]

主要提到四個可嘗試減少/避免的動作：

1. Data copies
2. Context switches
3. Memory allocation
4. Lock contention

### Data Copies

Data copies 該注意一些「不明顯」的，例如 hash function 不但有 data copy 還有計算，所以若要真減少或甚至達成 zero copy，得追很深才能確定。一個可用的實作方法是用間接存取，利用 buffer descriptor(s)，概念如下：

* A pointer and length for the whole buffer.
* A pointer and length, of offset and length, for the part of the buffer that's actually filled.
* Forward and back pointers to other buffer descriptors in a list.
* A reference count.

所以 copy 可以只是 reference count + 1，諸如此類。但當然到處都這樣做可能過於複雜，所以建議找出大的資料區塊使用即可。避免矯枉過正。

### Context Switches

相對於人人皆知要避免的 data copy，context switch 常被忽略，但實際更為嚴重。系統忙著從一個 thread 換到另一個，而無法真正有效的工作。最常見的 context switch 來源就是 active thread 數大於 CPU 數目。隨著 active thread 數上升，context switch 跟著增加，運氣好的話是線性，但常常是指數上升。這解釋了為何 one thread per connection 的架構很難擴增。唯一現實的替代方案是將 active thread 數限制在與 CPU 數目一致或更小。一個很受歡迎的變形是只用一個 thread，但缺點是只用到一顆 CPU，所以適合情形只有在瓶頸並非 CPU 時（經常是網路）。

少 thread 就必須採用某種處理多個連線的策略，這裡也提到 C10K 裡面的內容。作者認為 `select`/`poll` 與 signal 的方法都是 "ugly hacks"，而比較傾向 AIO 或 Windows 的 [I/O completion ports][]，但也說除了也許 `select` 以外都沒差多少，效果可以接受，但也沒有真正處理過了最外面的「門戶」之後發生的問題。

（個人覺得這是個重點，因為在最外面有個 nginx 之類快速處理連線的程式僅僅是門戶，但往往瓶頸是發生在進門之後。）

有個常見設計概念是以 listener thread 收連線放入 queue，然後交給 worker thread 去處理。但若實際這樣寫就錯了，因為第二常見的 context switch 原因就是將工作從一個 thread 轉到另一個。採用「平衡」設計是很重要的：thread 必須能從 listener 轉換為 worker 再轉回來而不改變 context。

但如何得知真正的 active thread 數目？可以直接用老派的 semaphore 計算，這也可把 maintenance thread 設計的較好。

一旦可做 listener - worker - listener 這樣轉換，很自然地就可以設計更多的階段 (stage)，而這些階段的串接方式可以由以下不同回傳值決定：

* The request needs to be passed on to another stage (an ID or pointer in the return value)
* The request has been completed (a special "request done" return value)
* The request was blocked (a special "request blocked" return value). This is equivalent to the previous case, except that the request is not freed and will be continued later from another thread.

這裡要注意 queuing 必須在每個階段「之內」做，而不是在外面放入下階段的 queue 之後呼叫下個階段然後馬上又 dequeue，這樣是沒有必要的。這類作法叫 Communicating Sequential Process [1]，但這裡的 process 是數學上的，而非限制這些行為必須在 OS 的同個 process 完成。基於這概念，作者認為 Matt Welsh's SEDA [2] 是較好的設計，並與他自己提出的方式做了如下比較：

1. SEDA's "batching" tends to emphasize processing multiple requests through a stage at once, while my approach tends to emphasize processing a single request through multiple stages at once.
2. SEDA's one significant flaw, in my opinion, is that it allocates a separate thread pool to each stage with only "background" reallocation of threads between stages in response to load. As a result, the #1 and #2 causes of context switches noted above are still very much present.
3. In the context of an academic research project, implementing SEDA in Java might make sense. In the real world, though, I think the choice can be characterized as unfortunate.

### Memory Allocation

1. Preallocation.
2. Lookaside list.（文內有介紹）
3. 用多個 lookaside list 來避免 lock.

### Lock Contention

Locking 兩難在於太簡單/太粗的話，原本可以平行處理的變成循序，犧牲效能與可擴充性，容易有 deadlock/livelock condition。但太細的話，則是 lock 所佔空間與 lock 運算所佔時間再度影響到效能，且易有 race condition. 以登山來譬喻，抵達山頂路徑往往有深谷等各種障礙，從一個大 lock 出發慢慢變小的方式，有如限制只能往上不能往下，往往難以抵達山頂。這邊提出的方法是，產生一張表格：

* The vertical axis represents code. If you're using a staged architecture with non-branching stages, you probably already have a diagram showing these divisions, like the ones everybody uses for OSI-model network protocol stacks.

* The horizontal axis represents data. In every stage, each request should be assigned to a data set with its own resources separate from any other set.

規則是：兩個 requests 絕不能互相競爭，除非他們屬於同個資料集以及同個處理階段。

接下來要設法合理的設計資料集與處理階段，使 lock 盡量縱橫平均分佈。文內有些建議，

If you have some sort of a block number or hash or transaction ID associated with requests, you can rarely do better than to divide that value by the number of data sets.

Sometimes, it's better to assign requests to data sets dynamically, based on which data set has the most resources available rather than some intrinsic property of the request. Think of it like multiple integer units in a modern CPU; those guys know a thing or two about making discrete requests flow through a system.

It's often helpful to make sure that the data-set assignment is different for each stage, so that requests which would contend at one stage are guaranteed not to do so at another stage.

若能平均分配，就是非常好的起點，此時就比較適合用切細的方式來進一步調整。

### 其他

As promised, I've covered the four biggest performance problems in server design. There are still some important issues that any particular server will need to address, though. Mostly, these come down to knowing your platform/environment:

* How does your storage subsystem perform with larger vs. smaller requests? With sequential vs. random? How well do read-ahead and write-behind work?

* How efficient is the network protocol you're using? Are there parameters or flags you can set to make it perform better? Are there facilities like TCP_CORK, MSG_PUSH, or the Nagle-toggling trick that you can use to avoid tiny messages?

* Does your system support scatter/gather I/O (e.g. readv/writev)? Using these can improve performance and also take much of the pain out of using buffer chains.

* What's your page size? What's your cache-line size? Is it worth it to align stuff on these boundaries? How expensive are system calls or context switches, relative to other things?

* Are your reader/writer lock primitives subject to starvation? Of whom? Do your events have "thundering herd" problems? Does your sleep/wakeup have the nasty (but very common) behavior that when X wakes Y a context switch to Y happens immediately even if X still has things to do?

I'm sure I could think of many more questions in this vein. I'm sure you could too. In any particular situation it might not be worthwhile to do anything about any one of these issues, but it's usually worth at least thinking about them. If you don't know the answers - many of which you will not find in the system documentation - find out. Write a test program or micro-benchmark to find the answers empirically; writing such code is a useful skill in and of itself anyway. If you're writing code to run on multiple platforms, many of these questions correlate with points where you should probably be abstracting functionality into per-platform libraries so you can realize a performance gain on that one platform that supports a particular feature.

The "know the answers" theory applies to your own code, too. Figure out what the important high-level operations in your code are, and time them under different conditions. This is not quite the same as traditional profiling; it's about measuring design elements, not actual implementations. Low-level optimization is generally the last resort of someone who screwed up the design.


\[1\]: Hoare, Charles Antony Richard. "Communicating sequential processes." _The origin of concurrent programming._ Springer New York, 1978. 413-443. ([pdf](papers/p666-hoare.pdf))

\[2\]: Welsh, Matt, David Culler, and Eric Brewer. "SEDA: an architecture for well-conditioned, scalable internet services." _ACM SIGOPS Operating Systems Review._ Vol. 35. No. 5. ACM, 2001. ([pdf](papers/Wel01.pdf))

[Unix Network Programming, Volume 1]: https://www.amazon.com/Unix-Network-Programming-Sockets-Networking/dp/0131411551/
[The 'thundering herd' problem]: http://www.citi.umich.edu/projects/linux-scalability/reports/accept.html
[Add epoll round robin wakeup mode]: https://lwn.net/Articles/632590/
[Jeff Darcy's notes on high-performance server design]: http://pl.atyp.us/content/tech/servers.html
[I/O completion ports]: https://msdn.microsoft.com/en-us/library/aa365198(VS.85).aspx
[Communicating Sequential Process]: http://cs2.ist.unomaha.edu/~stanw/papers/p666-hoare.pdf
